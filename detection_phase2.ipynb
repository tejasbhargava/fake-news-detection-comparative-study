{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f2dfc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\numpy\\__init__.py:111: UserWarning: mkl-service package failed to import, therefore Intel(R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see http://github.com/IntelPython/mkl-service\n",
      "  from . import _distributor_init\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb6ae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "063b833c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\ml\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b412e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ea0134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba6a910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"clean_data_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ff691f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>u.s. budget fight loom republicans flip fiscal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>u.s. military accept transgender recruit monda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>senior u.s. republican senator let mr. mueller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>fbi russia probe help australian diplomat tip ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>trump want postal service charge amazon shipme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE reported earl...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "      <td>mcpain john mccain furious iran treat sailors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "      <td>21st Century Wire says It s a familiar theme. ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "      <td>justice yahoo settles e mail privacy class act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>Sunnistan: US and Allied â€˜Safe Zoneâ€™ Plan to T...</td>\n",
       "      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 15, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunnistan: US and Allied â€˜Safe Zoneâ€™ Plan to T...</td>\n",
       "      <td>sunnistan allied safe zone plan territorial bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "      <td>21st Century Wire says Al Jazeera America will...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 14, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "      <td>blow $ al jazeera america finally call quit ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 12, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "      <td>u.s. navy sailors hold iranian military sign n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      As U.S. budget fight looms, Republicans flip t...   \n",
       "1      U.S. military to accept transgender recruits o...   \n",
       "2      Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3      FBI Russia probe helped by Australian diplomat...   \n",
       "4      Trump wants Postal Service to charge 'much mor...   \n",
       "...                                                  ...   \n",
       "44893  McPain: John McCain Furious That Iran Treated ...   \n",
       "44894  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "44895  Sunnistan: US and Allied â€˜Safe Zoneâ€™ Plan to T...   \n",
       "44896  How to Blow $700 Million: Al Jazeera America F...   \n",
       "44897  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "0      WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1      WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2      WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3      WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4      SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "...                                                  ...           ...   \n",
       "44893  21st Century Wire says As 21WIRE reported earl...   Middle-east   \n",
       "44894  21st Century Wire says It s a familiar theme. ...   Middle-east   \n",
       "44895  Patrick Henningsen  21st Century WireRemember ...   Middle-east   \n",
       "44896  21st Century Wire says Al Jazeera America will...   Middle-east   \n",
       "44897  21st Century Wire says As 21WIRE predicted in ...   Middle-east   \n",
       "\n",
       "                     date  label  \\\n",
       "0      December 31, 2017       1   \n",
       "1      December 29, 2017       1   \n",
       "2      December 31, 2017       1   \n",
       "3      December 30, 2017       1   \n",
       "4      December 29, 2017       1   \n",
       "...                   ...    ...   \n",
       "44893    January 16, 2016      0   \n",
       "44894    January 16, 2016      0   \n",
       "44895    January 15, 2016      0   \n",
       "44896    January 14, 2016      0   \n",
       "44897    January 12, 2016      0   \n",
       "\n",
       "                                                 content  \\\n",
       "0      As U.S. budget fight looms, Republicans flip t...   \n",
       "1      U.S. military to accept transgender recruits o...   \n",
       "2      Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3      FBI Russia probe helped by Australian diplomat...   \n",
       "4      Trump wants Postal Service to charge 'much mor...   \n",
       "...                                                  ...   \n",
       "44893  McPain: John McCain Furious That Iran Treated ...   \n",
       "44894  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "44895  Sunnistan: US and Allied â€˜Safe Zoneâ€™ Plan to T...   \n",
       "44896  How to Blow $700 Million: Al Jazeera America F...   \n",
       "44897  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                           clean_content  \n",
       "0      u.s. budget fight loom republicans flip fiscal...  \n",
       "1      u.s. military accept transgender recruit monda...  \n",
       "2      senior u.s. republican senator let mr. mueller...  \n",
       "3      fbi russia probe help australian diplomat tip ...  \n",
       "4      trump want postal service charge amazon shipme...  \n",
       "...                                                  ...  \n",
       "44893  mcpain john mccain furious iran treat sailors ...  \n",
       "44894  justice yahoo settles e mail privacy class act...  \n",
       "44895  sunnistan allied safe zone plan territorial bo...  \n",
       "44896  blow $ al jazeera america finally call quit ce...  \n",
       "44897  u.s. navy sailors hold iranian military sign n...  \n",
       "\n",
       "[44898 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b79006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"clean_content\"].astype(str)\n",
    "labels = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a06cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=\"clean_content\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb2c86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ae2dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test  = X_test.reset_index(drop=True)\n",
    "y_test  = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54c7dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "MAX_LEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79cc1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts.tolist() if hasattr(texts, \"tolist\") else list(texts)\n",
    "        self.labels = labels.tolist() if hasattr(labels, \"tolist\") else list(labels)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # ðŸ”¥ HANDLE BATCH INDICES\n",
    "        if isinstance(idx, (list, tuple)):\n",
    "            texts = [str(self.texts[i]) for i in idx]\n",
    "            labels = [self.labels[i] for i in idx]\n",
    "\n",
    "            encoding = self.tokenizer(\n",
    "                texts,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_len,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"input_ids\": encoding[\"input_ids\"],        # (batch, seq)\n",
    "                \"label\": torch.tensor(labels, dtype=torch.float32)\n",
    "            }\n",
    "\n",
    "        # ðŸ”¥ HANDLE SINGLE INDEX\n",
    "        if hasattr(idx, \"item\"):\n",
    "            idx = idx.item()\n",
    "        idx = int(idx)\n",
    "\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93abb34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(X_train, y_train, tokenizer, MAX_LEN)\n",
    "test_dataset  = TextDataset(X_test, y_test, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19d002ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        out = self.fc(hidden[-1])\n",
    "        return torch.sigmoid(out).squeeze(1)   # safer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0380c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            embed_dim,\n",
    "            hidden_dim,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)   # ðŸ”¥ doubled\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "\n",
    "        # forward + backward hidden states\n",
    "        hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "\n",
    "        out = self.fc(hidden)\n",
    "        return torch.sigmoid(out).squeeze(1)   # BCELoss compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dbfd6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1ee3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        X = batch[\"input_ids\"].to(device)\n",
    "        y = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba3a9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "model = LSTMModel(vocab_size, 128, 128)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8999ae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: torch.Size([32])\n",
      "y: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    X = batch[\"input_ids\"].to(device)\n",
    "    y = batch[\"label\"].to(device)\n",
    "\n",
    "    preds = model(X)\n",
    "\n",
    "    print(\"preds:\", preds.shape)\n",
    "    print(\"y:\", y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a2c2b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5  Loss: 0.6068\n",
      "Epoch 2/5  Loss: 0.1195\n",
      "Epoch 3/5  Loss: 0.0271\n",
      "Epoch 4/5  Loss: 0.0133\n",
      "Epoch 5/5  Loss: 0.0114\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}  Loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de04492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_metrics(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            X = batch[\"input_ids\"].to(device)\n",
    "            y = batch[\"label\"].to(device)\n",
    "\n",
    "            preds = model(X)\n",
    "            predicted = (preds >= 0.5).float()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    return acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b01e68d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9982\n",
      "Precision: 0.9995\n",
      "Recall   : 0.9967\n",
      "F1 Score : 0.9981\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f1 = evaluate_metrics(model, test_loader)\n",
    "\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41e91e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "bi_model = BiLSTMModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e5c68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(bi_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3beecda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.0435\n",
      "Epoch 2\n",
      "Train Loss: 0.0104\n",
      "Epoch 3\n",
      "Train Loss: 0.0097\n",
      "Epoch 4\n",
      "Train Loss: 0.0030\n",
      "Epoch 5\n",
      "Train Loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(bi_model, train_loader, optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61ccaccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9992\n",
      "Precision: 0.9993\n",
      "Recall   : 0.9991\n",
      "F1 Score : 0.9992\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f1 = evaluate_metrics(bi_model, test_loader)\n",
    "\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6ca345b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact duplicate samples: 1805\n",
      "\n",
      "Duplicate 1:\n",
      "mainstream media wonâ€™t new white house communications director anthony scaramucci explain call trump hack video mainstream medium side story hedge fund magnate anthony scaramucci appear fox business n\n",
      "\n",
      "Duplicate 2:\n",
      "arizona biker violent dreamer bad nightmare upcoming phoenix trump rally left itch fight problem ve itch fight trump supporter outnumber t fight bite bit chew time group biker say plan protect support\n",
      "\n",
      "Duplicate 3:\n",
      "breaking video obama state dept miraculously find + email ambassador chris stevens day hillary testimony great time joe biden announce hmmm wonder barack timing discovery email dirty chicago politic c\n",
      "\n",
      "Duplicate 4:\n",
      "cnn hack attempts gotcha moment trump immediately regret video watch cnn dana bash ask donald question wish didn t trump shut dana bash question take time attend hotel grand opening pic.twitter.com/lt\n",
      "\n",
      "Duplicate 5:\n",
      "army threatens green beret war hero court martial whistleblowing failed hostage rescue army t bother defend protect war hero busy pressing issue like ensure gay free come closet remove trace christian\n"
     ]
    }
   ],
   "source": [
    "train_set = set(X_train)\n",
    "test_set  = set(X_test)\n",
    "\n",
    "overlap = train_set.intersection(test_set)\n",
    "\n",
    "print(\"Exact duplicate samples:\", len(overlap))\n",
    "\n",
    "# show some examples\n",
    "for i, text in enumerate(list(overlap)[:5]):\n",
    "    print(f\"\\nDuplicate {i+1}:\\n{text[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a6e7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lstm(text, model, tokenizer, max_len=256):\n",
    "    model.eval()\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prob = model(input_ids)   # shape (1,)\n",
    "        pred = (prob >= 0.5).long().item()\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1ba78e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "text = \"U.S. economy grows at 1.4% rate in the fourth quarter, slower than expected\"\n",
    "pred = predict_lstm(text, model, tokenizer)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
