# ğŸ“° Fake News Detection System

A comparative study of classical machine learning, deep learning, and transformer-based models for fake news classification, integrated with Explainable AI and a real-time web interface.

---

## ğŸš€ Project Overview

This project investigates the effectiveness of different text representation and modeling approaches for fake news detection.  
The study compares:

- TF-IDF + Naive Bayes (Classical ML)
- LSTM
- BiLSTM
- BERT (Transformer)

The system also integrates SHAP-based explainability and a Streamlit web application for real-time inference.

---

## ğŸ“Š Model Performance

| Model                     | Accuracy |
|---------------------------|----------|
| TF-IDF + Naive Bayes      | 94.1%    |
| LSTM                      | 99.82%   |
| BiLSTM                    | 99.92%   |
| BERT                      | 99.90%   |

Deep sequential and transformer-based models demonstrated ~6% improvement over classical ML approaches.

---

## ğŸ§  Explainable AI

- Integrated SHAP to analyze feature/token contributions.
- Compared interpretability across sparse (TF-IDF) and contextual (BERT) representations.
- Studied challenges of explainability in deep transformer architectures.

---

## ğŸŒ Web Application

- Built using Streamlit
- Real-time text input for prediction
- Displays prediction probability
- Interactive inference interface

Run locally:

bash
pip install -r requirements.txt
streamlit run app.py
ğŸ›  Tech Stack

Python

PyTorch

HuggingFace Transformers

Scikit-learn

SHAP

Streamlit

ğŸ“‚ Project Structure

FAKE_NEWS_DETECTION/
â”‚â”€â”€ app.py
â”‚â”€â”€ detection_phase1.ipynb
â”‚â”€â”€ detection_phase2.ipynb
â”‚â”€â”€ detection_phase3.ipynb
â”‚â”€â”€ clean_data_merged.csv
â”‚â”€â”€ True.csv
â”‚â”€â”€ Fake.csv
â”‚â”€â”€ bert_fake_news_model/


##  ğŸ“¸ Application Screenshots

<p align="center">
  <img src="screenshots/pred.png" width="400"/>
</p>

<p align="center">
  <img src="screenshots/shap.png" width="500"/>
</p>